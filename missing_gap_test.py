#!/usr/bin/env python3
#
# Copyright 2020 Seth Troisi
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import argparse
import math
import multiprocessing
import re
import time

import gmpy2
import sqlite3
import tqdm

import gap_utils


def get_arg_parser():
    parser = argparse.ArgumentParser(
        "Test possible missing prime gaps generated by gap_stats")

    parser.add_argument('--save-logs', action='store_true',
        help="Save output to .log file")

    parser.add_argument("-t", "--threads", type=int, default=1, nargs="?",
        help="Number of threads to test with (default: %(default)s)")

    parser.add_argument('--search-db', type=str,
        default="prime-gap-search.db",
        help="Prime database from gap_test (default: %(default)s)")

    parser.add_argument("--unknown-filename", type=str, required=True,
        help="p, d, mstart, minc, sieve-length, and max-prime"
             " are determined from filename")

    parser.add_argument("-i", "--ignore-gaps", type=int,
        nargs="*", metavar="GAPS", default=[],
        help="Ignore these gap sizes")

    return parser


def parse_unknown_lines(args, probs, finished):
    skipped = 0

    # TODO --top-x-percent
    processed = []

    with open(args.unknown_filename) as unknown_file:
        for mi in tqdm.tqdm(range(args.minc)):
            m = args.mstart + mi
            if math.gcd(m, args.d) != 1: continue

            line = unknown_file.readline()
            assert line.startswith(str(mi)), (mi, line[:10])

            if m in finished:
                skipped += 1
                continue

            prob = probs[m]

            # parsing lines uses 8x space and runs on main thread.
            # passing 25k+ character strings is fast.
            processed.append((prob, m, line))

    # larger probs first
    processed.sort(reverse=True)

    return skipped, processed


def print_count_timing(s_start_t, prefix, count):
    secs = time.time() - s_start_t

    # Want 3 sig figs which is hard in python
    def roundSig(n, sig):
        return '{:g}'.format(float('{:.{p}g}'.format(n, p=sig)))

    if count and count < secs:
        timing = "{} secs/test".format(roundSig(secs / count, 3))
    else:
        timing = "{}/sec".format(roundSig(count / secs, 3))

    print("\t{:12} {:10d} tests ({})  {:.0f} seconds elapsed".format(
        prefix, count, timing, secs))


def load_existing(conn, args):
    # TODO: min_merit and to_process...
    rv = list(conn.execute(
        "SELECT rid FROM range"
        " WHERE P = ? AND D = ? AND m_start = ? AND m_inc = ?",
        (args.p, args.d, args.mstart, args.minc)))
    assert len(rv) == 1, rv
    rid = rv[0][0]

    rv = conn.execute(
        "SELECT m, prob_missing FROM m_stats"
        " WHERE P = ? AND D = ? AND m BETWEEN ? AND ?",
        (args.p, args.d, args.mstart, args.mstart + args.minc - 1))
    probs = {row['m']: row['prob_missing'] for row in rv}

    rv = conn.execute(
        "SELECT m FROM m_stats"
        " WHERE P = ? AND D = ? AND m BETWEEN ? AND ?"
        "    AND (prev_p != 0 OR prp_prev > 0 OR test_time > 0)",
        (args.p, args.d, args.mstart, args.mstart + args.minc - 1))
    finished = {row['m'] for row in rv}

    return rid, probs, finished


def save_record(
        conn, p, d,
        m, prev_p, next_p,
        prev_tests, next_tests, test_time):
    conn.execute(
        "UPDATE m_stats SET "
        "   prev_p=?, next_p=?,"
        "   prp_prev=?, prp_next=?,"
        "   test_time=test_time + ?"
        "WHERE P=? AND D=? AND M=?",
        (prev_p, next_p,
         prev_tests, next_tests,
         test_time,
         p, d, m))
    conn.commit()


# ----- Worker

# Makes tested/second much more stable
g_tested = multiprocessing.Value('i', 0)

def test_and_increment(p, start, str_diff):
    # counting before test seems to lead to stabler primes/second
    with g_tested.get_lock(): g_tested.value += 1
    return gap_utils.is_prime(p, start, str_diff)

# See Pool and initializer which set test_line.ignore_gaps
def init_worker(function, args):
    function.args = args

    # TODO: load from args or from sql
    # sqlite3 gaps.db "WITH RECURSIVE generate_series(value) AS (
    # SELECT 110000 UNION ALL SELECT value+2 FROM generate_series WHERE value+2 <= 133000
    # ) SELECT value || ',' FROM generate_series WHERE value NOT IN (select gapsize from gaps)"
    function.missing = [
        113326, 115694, 116254, 117238, 117242, 119222, 119584,
        120154, 121138, 121174, 121366, 121832, 122290, 122666,
        122686, 123230, 123238, 123242, 123598, 123662, 123782,
        124106, 124258, 124346, 124534, 124792, 125024, 125318,
        125974, 126134, 126206, 126236, 126298, 126376, 126394,
        126538, 126554, 126814, 127346, 127544, 127622, 127732,
        127906, 128114, 128362, 128372, 128516, 128686, 128714,
        128762, 128872, 129298, 129406, 129538, 129698, 129754,
        129784, 130042, 130162, 130252, 130280, 130282, 130310,
        130438, 130798, 130846, 130882, 130898, 131074, 131288,
        131378, 131402, 131446, 131530, 131536, 131564, 131578,
        131648, 131762, 131788, 131876, 131938, 131954, 132130,
        132194, 132206, 132218, 132232, 132242, 132302, 132314,
        132446, 132506, 132548, 132598, 132644, 132838, 132842,
        132848, 132928, 132958, 132992, 132994,
    ]

    for ignore in test_line.args.ignore_gaps:
        if ignore in function.missing:
            function.missing.remove(ignore)


def test_line(data):
    prob, m, line = data

    start = f"{m} * {test_line.args.p}# / {test_line.args.d}"
    K, r = divmod(gmpy2.primorial(test_line.args.p), test_line.args.d)
    assert r == 0
    N = m * K

    mtest, unknown_l, unknown_u, unknowns = \
        gap_utils.parse_unknown_line(line)

    t0 = time.time()

    prime_low  = 0
    prime_high = 0

    prp_low = 0
    prp_high = 0

    for low in unknowns[0]:
        assert low < 0
        low = abs(low)

        # In theory stop, but SO LARGE keep running.
        #if low > test_line.missing[-1]:
        #    break

        # use - for low so that (N - x) doesn't conflict with (N + x)
        prp_low += 1
        if not test_and_increment(N - low, start, "-" + str(low)):
            continue

        prime_low = low

        for gap in test_line.missing:
            assert gap not in test_line.args.ignore_gaps

            if gap <= low:
                continue

            high = gap - low
            # XXX: binary search or set
            if high not in unknowns[1]:
                continue

            prp_high += 1
            if test_and_increment(N + high, start, "+" + str(high)):
                prime_high = high
                break

        break


    t1 = time.time()

    return (
        # input data copied to output
        prob, m,
        # top level output counters
        prp_low, prp_high, t1 - t0,
        # primes found
        prime_low, prime_high
    )


def prime_gap_test(args):

    # ----- Open missing gap input file
    print("Loading unknowns from '{}'".format(args.unknown_filename))

    print("Loading finished records from '{}'".format(args.search_db))

    conn = sqlite3.connect(args.search_db)
    conn.row_factory = sqlite3.Row
    rid, probs, finished = load_existing(conn, args)
    if probs:
        print("\tFound {} (m {} to {}) ({} already processed)".format(
            len(probs), min(probs), max(probs), len(finished)))
    else:
        print("Already processed({}) everything".format(len(finished)))
        exit(1)

    print()

    if args.ignore_gaps:
        print("\tSkipping gaps: {}\n".format(
            ", ".join(map(str, args.ignore_gaps))))

    K, K_digits, K_bits, K_log = gap_utils.K_and_stats(args)
    print("K = {} bits, {} digits, log(K) = {:.2f}\n".format(
        K_bits, K_digits, K_log))

    # Used for various stats
    s_start_t = time.time()
    s_last_print_t = time.time()
    s_last_success_count = 0

    successes = []
    summed_prob = 0
    tested = 0
    primes = 0

    skipped_lines, lines = parse_unknown_lines(args, probs, finished)
    if len(lines) == 0:
        print("All {} lines already processed".format(skipped_lines))
        # Could have processed other m from other runs.
        assert skipped_lines <= len(finished)
        exit(1)

    print("Read {} lines ({} already processed) with missing_gap_prob: {:.3g} to {:.3g}".format(
        len(lines), skipped_lines, lines[0][0], lines[-1][0]))

    probs = [line[0] for line in lines]
    assert max(probs) == lines[0][0], "Out of order lines!"
    assert min(probs) == lines[-1][0], "Out of order lines!"

    # Pass *init_args to initializer
    init_args = (test_line, args)

    with multiprocessing.Pool(args.threads, init_worker, init_args) as pool:
        for li, (prob, m, test_low, test_high, test_time, prev_p, next_p) in \
                enumerate(pool.imap_unordered(test_line, lines)):
            start = f"{m} * {args.p}# / {args.d}"

            # XXX: load gaps.db and verify this is a missing gap?
            if prev_p and next_p:
                succ = "BOTH PRIME: {} -{} to +{}".format(start, prev_p, next_p)
                successes.append(succ)
                print("\n"*3)
                print("\t", succ)
                print("\n"*3)

            # NOTE: -next_p indicates prime, but not necessarily first.
            save_record(
                conn, args.p, args.d,
                m, prev_p, -next_p,
                test_low, test_high, test_time)

            summed_prob += prob
            tested  += test_low + test_high
            primes  += (prev_p != 0) + (next_p != 0)

            s_stop_t = time.time()
            secs = s_stop_t - s_start_t
            print_secs = s_stop_t - s_last_print_t

            print("finished: {} ({:.2e})\t|".format(start, prob), end = " ")

            li1 = li + 1

            # Adjusted a little to make `per_day` more stable
            avg_test = secs / li1
            adj_secs = max(avg_test, secs - (avg_test * args.threads / 2))
            per_day = "  per day: {:.3f}".format(summed_prob / (adj_secs / 86400))

            print("m: {}/{}, p/t: {}/{}, sum(prob): {:.4f}{}".format(
                li + 1, len(lines),
                primes, tested,
                summed_prob, per_day if 2 * li >= args.threads else ""))

            if li1 in (1,2,5,10,20,50, len(lines)) or li1 % 100 == 0 or print_secs > 240:
                s_last_print_t = s_stop_t

                # TODO: eta for finishing
                with g_tested.get_lock():
                    print_count_timing(s_start_t, li1, g_tested.value)

                if len(successes) - s_last_success_count >= 5:
                    print("\n"*2)
                    for success in successes[s_last_success_count:]:
                        print("\t", success)
                    print("\n"*2)
                    s_last_success_count = len(successes)

    print_count_timing(s_start_t, "END: " + str(li + 1), tested)

    print("\n"*2)
    print("All successes ({} from {} prob):".format(
        len(successes), summed_prob))
    for success in successes:
        print("\t", success)
    print("\n"*2)


if __name__ == "__main__":
    parser = get_arg_parser()
    args = parser.parse_args()
    gap_utils.verify_args(args)

    # TeeLogger context if args.save_logs
    with gap_utils.logger_context(args):
        prime_gap_test(args)

